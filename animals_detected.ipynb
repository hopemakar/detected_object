{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7a7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9f872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 20:07:10.827618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-04 20:07:10.827649: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import humanfriendly\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1d260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIDENCE_THRESHOLD = 0.85\n",
    "DETECTION_FILENAME_INSERT = '_detections'\n",
    "EMPTY_FILENAME_INSERT = \"_empty\"\n",
    "\n",
    "DEFAULT_LINE_WIDTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a7eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_categories = [\n",
    "    {'id': 0, 'name': 'empty'},\n",
    "    {'id': 1, 'name': 'animal'},\n",
    "    {'id': 2, 'name': 'person'},\n",
    "    {'id': 3, 'name': 'group'},\n",
    "    {'id': 4, 'name': 'vehicle'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ca7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_category_str_id_to_name = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in bbox_categories:\n",
    "    bbox_category_str_id_to_name[str(cat['id'])] = cat['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b50a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint):\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(checkpoint, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "    return detection_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef846525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detections(detection_graph,images):\n",
    "\n",
    "    if not isinstance(images,list):\n",
    "        images = [images]\n",
    "    else:\n",
    "        images = images.copy()\n",
    "\n",
    "    print('Loading images...')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iImage,image in enumerate(tqdm(images)):\n",
    "        if isinstance(image,str):\n",
    "            \n",
    "            image = PIL.Image.open(image).convert(\"RGB\")\n",
    "            image = np.array(image)\n",
    "\n",
    "            nChannels = image.shape[2]\n",
    "            if nChannels > 3:\n",
    "                print('Warning: trimming channels from image')\n",
    "                image = image[:,:,0:3]\n",
    "            images[iImage] = image\n",
    "        else:\n",
    "            assert isinstance(image,np.ndarray)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Finished loading {} file(s) in {}\".format(len(images),\n",
    "          humanfriendly.format_timespan(elapsed)))    \n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    classes = []\n",
    "    \n",
    "    n_images = len(images)\n",
    "\n",
    "    print('Running detector...')    \n",
    "    start_time = time.time()\n",
    "    first_image_complete_time = None\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        \n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            for iImage,imageNP in tqdm(enumerate(images)): \n",
    "                \n",
    "                imageNP_expanded = np.expand_dims(imageNP, axis=0)\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                box = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                score = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                clss = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                \n",
    "                (box, score, clss, num_detections) = sess.run(\n",
    "                        [box, score, clss, num_detections],\n",
    "                        feed_dict={image_tensor: imageNP_expanded})\n",
    "\n",
    "                boxes.append(box)\n",
    "                scores.append(score)\n",
    "                classes.append(clss)\n",
    "            \n",
    "                if iImage == 0:\n",
    "                    first_image_complete_time = time.time()\n",
    "                    \n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    if n_images == 1:\n",
    "        print(\"Finished running detector in {}\".format(humanfriendly.format_timespan(elapsed)))\n",
    "    else:\n",
    "        first_image_elapsed = first_image_complete_time - start_time\n",
    "        remaining_images_elapsed = elapsed - first_image_elapsed\n",
    "        remaining_images_time_per_image = remaining_images_elapsed/(n_images-1)\n",
    "        \n",
    "        print(\"Finished running detector on {} images in {} ({} for the first image, {} for each subsequent image)\".format(len(images),\n",
    "              humanfriendly.format_timespan(elapsed),\n",
    "              humanfriendly.format_timespan(first_image_elapsed),\n",
    "              humanfriendly.format_timespan(remaining_images_time_per_image)))\n",
    "    \n",
    "    n_boxes = len(boxes)\n",
    "\n",
    "    n_detections = -1\n",
    "\n",
    "    for iBox,box in enumerate(boxes):\n",
    "        n_detections_this_box = box.shape[1]\n",
    "        assert (n_detections == -1 or n_detections_this_box == n_detections), 'Detection count mismatch'\n",
    "        n_detections = n_detections_this_box\n",
    "        assert(box.shape[0] == 1)\n",
    "    \n",
    "\n",
    "    assert(len(scores) == n_images)\n",
    "    for(iScore,score) in enumerate(scores):\n",
    "        assert score.shape[0] == 1\n",
    "        assert score.shape[1] == n_detections\n",
    "        \n",
    "    assert(len(classes) == n_boxes)\n",
    "    for(iClass,c) in enumerate(classes):\n",
    "        assert c.shape[0] == 1\n",
    "        assert c.shape[1] == n_detections\n",
    "            \n",
    "    boxes = np.squeeze(np.array(boxes),axis=1)\n",
    "    scores = np.squeeze(np.array(scores),axis=1)\n",
    "    classes = np.squeeze(np.array(classes),axis=1).astype(int)\n",
    "    \n",
    "    assert(len(boxes.shape) == 3)\n",
    "    assert(boxes.shape[0] == n_images)\n",
    "    assert(boxes.shape[1] == n_detections)\n",
    "    assert(boxes.shape[2] == 4)\n",
    "    \n",
    "    assert(len(scores.shape) == 2)\n",
    "    assert(scores.shape[0] == n_images)\n",
    "    assert(scores.shape[1] == n_detections)\n",
    "    \n",
    "    assert(len(classes.shape) == 2)\n",
    "    assert(classes.shape[0] == n_images)\n",
    "    assert(classes.shape[1] == n_detections)\n",
    "\n",
    "    return boxes,scores,classes,images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcb4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_detection_bounding_boxes(detections, image, draw_boxes=True, label_map={},\n",
    "                                    classification_label_map={},\n",
    "                                    confidence_threshold=0.8, thickness=4,\n",
    "                                    classification_confidence_threshold=0.3,\n",
    "                                    max_classifications=3):\n",
    " \n",
    "    display_boxes = []\n",
    "    display_strs = []\n",
    "    classes = []\n",
    "\n",
    "    for detection in detections:\n",
    "\n",
    "        score = detection['conf']\n",
    "        if score > confidence_threshold:\n",
    "            \n",
    "            x1, y1, w_box, h_box = detection['bbox']\n",
    "            display_boxes.append([y1, x1, y1 + h_box, x1 + w_box])\n",
    "            clss = detection['category']\n",
    "            label = label_map[clss] if clss in label_map else clss\n",
    "            displayed_label = ['{}: {}%'.format(label, round(100 * score))]\n",
    "            \n",
    "            if 'classifications' in detection:\n",
    "                \n",
    "                print(\"Classification start...\")\n",
    "                clss = len(bbox_categories) + int(detection['classifications'][0][0])\n",
    "                classifications = detection['classifications']\n",
    "                if len(classifications) > max_classifications:\n",
    "                    classifications = classifications[0:max_classifications]\n",
    "                for classification in classifications:\n",
    "                    p = classification[1]\n",
    "                    if p < classification_confidence_threshold:\n",
    "                        continue\n",
    "                    class_key = classification[0]\n",
    "                    if class_key in classification_label_map:\n",
    "                        class_name = classification_label_map[class_key]\n",
    "                    else:\n",
    "                        class_name = class_key\n",
    "                    displayed_label += ['{}: {:5.1%}'.format(class_name.lower(), classification[1])]\n",
    "\n",
    "            display_strs.append(displayed_label)\n",
    "            classes.append(clss)\n",
    "\n",
    "    display_boxes = np.array(display_boxes)\n",
    "    \n",
    "    if draw_boxes:\n",
    "        draw_bounding_boxes_on_image(image, display_boxes, classes,\n",
    "                                     display_strs=display_strs, thickness=thickness)\n",
    "    \n",
    "    return display_strs\n",
    "\n",
    "\n",
    "COLORS = [\n",
    "    'AliceBlue', 'Red', 'RoyalBlue', 'Gold', 'Chartreuse', 'Aqua',  'Azure', \n",
    "    'Beige', 'Bisque', 'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue',\n",
    "    'AntiqueWhite', 'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson',\n",
    "    'Cyan', 'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'RosyBrown', 'Aquamarine', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa3d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_on_image(image,\n",
    "                                 boxes,\n",
    "                                 classes,\n",
    "                                 thickness=4,\n",
    "                                 display_strs=()):\n",
    "\n",
    "    boxes_shape = boxes.shape\n",
    "    if not boxes_shape:\n",
    "        return\n",
    "    if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "        return\n",
    "    for i in range(boxes_shape[0]):\n",
    "        if display_strs:\n",
    "            display_str_list = display_strs[i]\n",
    "            draw_bounding_box_on_image(image,\n",
    "                                       boxes[i, 0], boxes[i, 1], boxes[i, 2], boxes[i, 3],\n",
    "                                       classes[i],\n",
    "                                       thickness=thickness, display_str_list=display_str_list)\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               clss=None,\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True,\n",
    "                               label_font_size=16):\n",
    " \n",
    "    if clss is None:\n",
    "        color = COLORS[1]\n",
    "    else:\n",
    "        color = COLORS[int(clss) % len(COLORS)]\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    if use_normalized_coordinates:\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                      ymin * im_height, ymax * im_height)\n",
    "    else:\n",
    "        (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "               (right, top), (left, top)], width=thickness, fill=color)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype('arial.ttf', label_font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = bottom + total_display_str_height\n",
    "\n",
    "    for display_str in display_str_list[::-1]:\n",
    "\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "\n",
    "        draw.rectangle(\n",
    "            [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                              text_bottom)],\n",
    "            fill=color)\n",
    "\n",
    "        draw.text(\n",
    "            (left + margin, text_bottom - text_height - margin),\n",
    "            display_str,\n",
    "            fill='black',\n",
    "            font=font)\n",
    "\n",
    "        text_bottom -= (text_height + 2 * margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c339aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_bounding_box(box, score, class_label, input_file_name, output_file_name=None,\n",
    "                          confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD,linewidth=DEFAULT_LINE_WIDTH):\n",
    "\n",
    "    output_file_names = []\n",
    "    if output_file_name is not None:\n",
    "        output_file_names = [output_file_name]\n",
    "    scores = [[score]]\n",
    "    boxes = [[box]]\n",
    "    categories = render_bounding_boxes(boxes,scores,[class_label],[input_file_name],\n",
    "                                       output_file_names,confidence_threshold,linewidth)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fb26d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_bounding_boxes(boxes, scores, classes, input_file_names, output_file_names=[],\n",
    "                          draw_boxes=True, confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD, \n",
    "                          linewidth=DEFAULT_LINE_WIDTH):\n",
    "\n",
    "    n_images = len(input_file_names)\n",
    "    iImage = 0\n",
    "    categories = []\n",
    "    \n",
    "    for iImage in range(0,n_images):\n",
    "\n",
    "        input_file_name = input_file_names[iImage]\n",
    "\n",
    "        if iImage >= len(output_file_names):\n",
    "            output_file_name = ''\n",
    "        else:\n",
    "            output_file_name = output_file_names[iImage]\n",
    "\n",
    "        image = PIL.Image.open(input_file_name).convert(\"RGB\")\n",
    "        detections = []\n",
    "        \n",
    "        for iBox in range(0,len(boxes)):\n",
    "            \n",
    "            bbox_in = boxes[iImage][iBox]\n",
    "            bbox = [bbox_in[1],\n",
    "                    bbox_in[0], \n",
    "                    bbox_in[3]-bbox_in[1],\n",
    "                    bbox_in[2]-bbox_in[0]]\n",
    "            \n",
    "            detections.append({'category':str(classes[iImage][iBox]),\n",
    "                      'conf':scores[iImage][iBox],\n",
    "                      'bbox':bbox})\n",
    "            \n",
    "        class_cat = render_detection_bounding_boxes(detections, image, draw_boxes=draw_boxes,\n",
    "                                                confidence_threshold=confidence_threshold, \n",
    "                                                thickness=linewidth,\n",
    "                                                label_map=bbox_category_str_id_to_name)\n",
    "        if class_cat[0]:\n",
    "            name_of_dir = class_cat[0][0].partition(':')[0]\n",
    "            output_file_name.replace(\"detected\", name_of_dir)\n",
    "        categories.append(class_cat)\n",
    "        if len(output_file_name) == 0:\n",
    "            print(len(output_file_name))\n",
    "            name, ext = os.path.splitext(input_file_name)\n",
    "            output_file_name = \"{}{}{}\".format(name,DETECTION_FILENAME_INSERT,ext)\n",
    "            \n",
    "#         image.save(output_file_name)\n",
    "\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e88cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_run_detector(model_file, image_file_names, output_dir=None, draw_boxes=True,\n",
    "                          confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD, \n",
    "                          detection_graph=None):\n",
    "    \n",
    "    if len(image_file_names) == 0:        \n",
    "        print('Warning: no files available')\n",
    "        return\n",
    "        \n",
    "    # Load and run detector on target images\n",
    "    print('Loading model...')\n",
    "    start_time = time.time()\n",
    "    if detection_graph is None:\n",
    "        detection_graph = load_model(model_file)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Loaded model in {}\".format(humanfriendly.format_timespan(elapsed)))\n",
    "    \n",
    "    boxes,scores,classes,images = generate_detections(detection_graph,image_file_names)\n",
    "    \n",
    "    assert len(boxes) == len(image_file_names)\n",
    "    \n",
    "    print('Rendering output...')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_full_paths = []\n",
    "    output_file_names = {}\n",
    "    \n",
    "    if output_dir is not None:\n",
    "            \n",
    "        os.makedirs(output_dir,exist_ok=True)\n",
    "        \n",
    "        for iFn,fullInputPath in enumerate(tqdm(image_file_names)):\n",
    "            \n",
    "            fn = os.path.basename(fullInputPath).lower()            \n",
    "            name, ext = os.path.splitext(fn)\n",
    "            fn = \"{}{}{}\".format(name,DETECTION_FILENAME_INSERT,ext)\n",
    "            \n",
    "            # Since we'll be writing a bunch of files to the same folder, rename\n",
    "            # as necessary to avoid collisions\n",
    "            if fn in output_file_names:\n",
    "                nCollisions = output_file_names[fn]\n",
    "                fn = str(nCollisions) + '_' + fn\n",
    "                output_file_names[fn] = nCollisions + 1\n",
    "            else:\n",
    "                output_file_names[fn] = 0\n",
    "\n",
    "            output_full_paths.append(os.path.join(output_dir,fn))\n",
    "    render_bounding_boxes(boxes=boxes, scores=scores, \n",
    "                          classes=classes, \n",
    "                          input_file_names=image_file_names, \n",
    "                          output_file_names=output_full_paths,\n",
    "                          draw_boxes = draw_boxes,\n",
    "                          confidence_threshold=confidence_threshold)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Rendered output in {}\".format(humanfriendly.format_timespan(elapsed)))\n",
    "    \n",
    "    return detection_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    input_dir = r'/home/makar/Documents/netology/cv/data' \n",
    "    image_file_names = []\n",
    "    output_dir = \"/home/makar/Documents/netology/cv/detected\"\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            image_file_names.append(os.path.join(root,file))\n",
    "\n",
    "    print('Running detector on {} images'.format(len(image_file_names)))    \n",
    "    \n",
    "    load_and_run_detector(model_file='/home/makar/Documents/netology/cv/md_v4.1.0.pb', \n",
    "                        image_file_names=image_file_names, \n",
    "                        confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD, \n",
    "                        output_dir=output_dir, draw_boxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6c5117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running detector on 4 images\n",
      "Loading model...\n",
      "Loaded model in 14.11 seconds\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  2.45it/s]\n",
      "2021-12-04 20:07:30.026112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-04 20:07:30.026150: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-04 20:07:30.026179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 4 file(s) in 1.64 seconds\n",
      "Running detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:37, 54.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running detector on 4 images in 3 minutes and 37.17 seconds (1 minute and 2.06 seconds for the first image, 51.7 seconds for each subsequent image)\n",
      "Rendering output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 4/4 [00:00<00:00, 27413.75it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15452/3380403066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15452/4086830617.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running detector on {} images'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     load_and_run_detector(model_file='/home/makar/Documents/netology/cv/md_v4.1.0.pb', \n\u001b[0m\u001b[1;32m     13\u001b[0m                         \u001b[0mimage_file_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_file_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mconfidence_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_CONFIDENCE_THRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15452/3866359529.py\u001b[0m in \u001b[0;36mload_and_run_detector\u001b[0;34m(model_file, image_file_names, output_dir, draw_boxes, confidence_threshold, detection_graph)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moutput_full_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     render_bounding_boxes(boxes=boxes, scores=scores, \n\u001b[0m\u001b[1;32m     48\u001b[0m                           \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                           \u001b[0minput_file_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_file_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15452/2402223883.py\u001b[0m in \u001b[0;36mrender_bounding_boxes\u001b[0;34m(boxes, scores, classes, input_file_names, output_file_names, draw_boxes, confidence_threshold, linewidth)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                 \u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                 label_map=bbox_category_str_id_to_name)\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclass_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mname_of_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moutput_file_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detected\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_of_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb649c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d0543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb3485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191ac73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
